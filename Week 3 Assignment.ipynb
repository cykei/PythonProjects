{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VEj1vZKLhUv4"
   },
   "source": [
    "# Week 3 Assignment: Cat Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwZpqmzBhUv6"
   },
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eg1wahLZhUv7"
   },
   "source": [
    "## <font color=\"red\"> <참고사항> \n",
    "\n",
    "### 3주차와 4주차의 과제 난이도가 입문자들에게는 매우 높습니다. 그럼에도 하는 이유가 뭘까요?\n",
    "    \n",
    "#### 1. Neural Network의 구조에 대해 어느 정도 알아야 tensorflow로 구현할 수 있습니다.\n",
    "- 하지만 5주차 초반부까지 가야 Neural Network의 구조에 대해 다 배웁니다.\n",
    "    \n",
    "- 그래서 실질적으로 더 열심히 하셔야 하는 과제는 5주차 이후의 과제들입니다.\n",
    " \n",
    "#### 2. 그 전까지는 여러분들이 python과 numpy에 대해 실습을 통해 공부할 필요가 있습니다.\n",
    "- 3~4주차 과제를 하시면서 모르는 부분들이 많을 것입니다.\n",
    "    \n",
    "- 이 부분을 직접 찾아보거나 튜터에게 질문을 하며 과제를 구현하게 되면 향후 python 실력이 5주차 실습을 하기에 충분해집니다.\n",
    "    \n",
    "#### 3. 또한, 이 과제는 코세라 내용을 기반으로 하기 때문에 배운 내용을 간접적으로 한 번 더 복습할 수 있는 계기가 됩니다.\n",
    "    \n",
    "### <font color=\"coral\"> **결론 1:** python 공부와 강의 복습을 목적으로 이 과제를 최대한 해결하되 \n",
    "### <font color=\"coral\"> 과제를 다 해결하지 못해도 tensorflow 구조가 이보다 쉽기 때문에 충분히 5주차 이후 실습이 가능합니다.\n",
    "    \n",
    "    \n",
    "### <font color=\"coral\"> **결론 2:** 빈칸이 이외의 셀은 알지 못해도 됩니다. (필요한 부분은 수업시간에 안내합니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-aCDqvwHhUv7"
   },
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gJyTYOIkhUv8"
   },
   "source": [
    "## assignment 관련 설명 (꼭 읽어보시고 시작하시기 바랍니다.)\n",
    "\n",
    "### <font color=\"red\"> 0. 로컬 컴퓨터에서 진행하시는 경우 폴더 통째로 받아서 'images' 폴더랑 'Week 3 Assignment.ipynb'를 같은 폴더에 넣고 시작하셔야 합니다.\n",
    "\n",
    "### 1. 기본\n",
    "\n",
    "1) 기본: 'shift + enter' 로 각 셀을 실행합니다.\n",
    "\n",
    "2) ###START CODE HERE ### 와 ### END CODE HERE ### 사이의 빈 칸에 답을 적으시면 됩니다.\n",
    "\n",
    "3) (= X lines of code) 라고 적혀 있으면, X개의 줄 만큼의 답을 적으시면 됩니다. (물론 x개의 줄이 아니어도 정답일 수 있습니다.)\n",
    "\n",
    "4) 빈칸 이외의 부분은 건드리지 말아주세요.\n",
    "\n",
    "5) 셀은 위에서부터 **순서대로** 실행해주세요.\n",
    "\n",
    "6) 여유가 되신다면 빈칸 이외의 부분도 관심을 가지고 공부하는 것도 추천드립니다.\n",
    "\n",
    "#### 7) 문제와 주석을 꼼꼼히 읽어보시면 분명 hint가 나옵니다.  \n",
    "\n",
    "### 2. 자꾸 error 가 날 때\n",
    "  \n",
    "1) 처음부터 끝까지 순서대로 다시 실행 (특히, import 했는지 확인해보기)\n",
    "\n",
    "2) 문제를 잘 읽었는지 확인해보기\n",
    "\n",
    "3) 대소문자를 구별해서 적었는지 확인해주세요.\n",
    "\n",
    "4) 튜터에게 error 부분 스샷 잘 찍어서 질문하기\n",
    "\n",
    "### 3. 셀이 실행 안 될 때\n",
    "\n",
    "1) 좌측 상단에서 kernel -> Restart kernel 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ITN9i-6ohUv9"
   },
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dtFzbXUehUv9"
   },
   "source": [
    "## 1. Import Packages ##\n",
    "\n",
    "<중요한 라이브러리>\n",
    "- [numpy](www.numpy.org)는 2주차 수업 때 간단히 배웠으며 ndarray를 다루는 라이브러리입니다.\n",
    "- [matplotlib](http://matplotlib.org)은 셀 안에 그래프 혹은 그림을 그려줘서 향후 여러분들이 많이 쓰게 될 라이브러리이며 9주차에 특강으로 학습하실 수 있습니다.\n",
    "\n",
    "<알지 못해도 되는 라이브러리>\n",
    "- [h5py](http://www.h5py.org)는 H5 파일을 다루는 라이브러리이며 향후 딥러닝 NN구조와 parameter를 저장할 때 H5 파일 형태로 저장합니다.\n",
    "- [PIL](http://www.pythonware.com/products/pil/) and [cv2(opecnv)](https://opencv.org/) 는 마지막에 보너스로 여러분의 이미지를 test할 때 쓰이는 이미지 다루는 라이브러리입니다.\n",
    "\n",
    "\n",
    "이 라이브러리들을 사용하기 위해 아래 셀을 실행해주어야 합니다.  \n",
    "\n",
    "혹시 \"No module named 'cv2'\" 라는 에러가 뜬다면  \n",
    "\n",
    "    !pip install opencv-python\n",
    "이라는 명령어를 실행시켜서 opencv 라이브러리를 설치해주세요.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8SjNVlwahUv-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import cv2\n",
    "import PIL.Image as pilimg\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tSbxSokChUwB"
   },
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CVOqrEgihUwB"
   },
   "source": [
    "## 2. Data (업로드, 확인, 전처리) ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwLrdhyDhUwC"
   },
   "source": [
    "### 2-1) data 업로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1r8hrPOPlxr-"
   },
   "source": [
    "아래 셀을 colab에서 구글 드라이브로 실행할 경우는\n",
    "우선 아래 코드를 통해 google drive를 mount 하신 뒤에  \n",
    "```python\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "```\n",
    "/content/gdrive/My Drive/ 폴더에, 즉 '내 드라이브' 폴더에 image 폴더를 두신 뒤, load_dataset 함수의 정의 부분에서 train_dataset과 test_dataset을 불러오는 부분을  \n",
    "```python\n",
    "train_dataset = h5py.File('/content/gdrive/My Drive/images/train_catvnoncat.h5', \"r\")\n",
    "test_dataset = h5py.File('/content/gdrive/My Drive/images/test_catvnoncat.h5', \"r\")\n",
    "```\n",
    "로 고쳐주시면 됩니다.\n",
    "혹은 아래 코드를 통해 working directory를 현재 폴더로 하셔도 됩니다. ('working_directory_path' 대신 현재 폴더의 path를 적어주세요)\n",
    "```python\n",
    "import os\n",
    "os.chdir('working_directory_path')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eg4E6LDQhUwD"
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train_dataset = h5py.File('images/train_catvnoncat.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y= np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('images/test_catvnoncat.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array([b'non-cat', b'cat']) # the list of classes\n",
    "    train_set_y= train_set_y.reshape((1, train_set_y.shape[0]))\n",
    "    test_set_y = test_set_y.reshape((1, test_set_y.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 779,
     "status": "error",
     "timestamp": 1578749241533,
     "user": {
      "displayName": "박은천",
      "photoUrl": "",
      "userId": "14521844370247226015"
     },
     "user_tz": -540
    },
    "id": "YqBopCdKhUwE",
    "outputId": "41328f39-d8d3-4691-b195-516b9fdfca15"
   },
   "outputs": [],
   "source": [
    "# Loading the data (cat/non-cat)\n",
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eCmXJuyOhUwG"
   },
   "source": [
    "**data에 대한 이해**: You are given a dataset (\"data.h5\"에 저장되어 있음) containing:\n",
    "\n",
    "- a training set of m_train images labeled as cat (y=1) or non-cat (y=0)\n",
    "- a test set of m_test images labeled as cat or non-cat\n",
    "- each image is of shape (num_px, num_px, 3) where 3 is for the 3 channels (RGB). Thus, each image is square (height = num_px) and (width = num_px).\n",
    "\n",
    "**<부연>**\n",
    "\n",
    "1) training set은 우리의 모델을 학습시키기 위해 사용하는 dataset\n",
    "\n",
    "2) test set은 학습된 모델이 학습하지 않은 data(test data)에서도 일관되게 성능이 나오는지 확인하기 위한 data (일반성을 확보하기 위해 존재) (5주차에 배웁니다.)\n",
    "\n",
    "3) 이미지 1개 (x(i))의 shape = (num_px, num_px, 3)이다.\n",
    "- (3은 RGB 채널 각각을 의미)\n",
    "- (num_px,num_px) = 세로 픽셀 수(행의 개수), 가로 픽셀 수(열의 개수)\n",
    "\n",
    "4) train_set_x_orig에는 training data(shape=num_px, num_px, 3)가 m개 있다.\n",
    " **=> train_set_x_orig.shape = (m, num_px, num_px, 3)**\n",
    "\n",
    "5) 실제 data 업로드 방법은 이와 다르니 위의 업로드를 유심히 보지 않아도 됩니다.\n",
    "\n",
    "6) \"_orig\"는 문제를 만든 사람이 아직 data가 전처리(preprocess)가 안 되었다는 것을 알려주기 위해 변수 이름에 덧붙였다.\n",
    "\n",
    "(물론 ndarray가 어떻게 생겼을지는 아무도 모릅니다. 그래서 항상 shape을 찍어보는 습관을 들이기 바랍니다.)\n",
    "\n",
    "(이를 통해 향후 2주의 과제로 ndarray에 익숙해지는 시간을 가지기 바랍니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J0QTKZREhUwH"
   },
   "source": [
    "### 2-2) data 확인\n",
    "\n",
    "#### matplotlib.pyplot가 주로 사용되는 2가지\n",
    "- data 업로드가 잘 되었는지 확인\n",
    "- 학습이 잘 되었는지 그래프 그릴 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 633,
     "status": "ok",
     "timestamp": 1578729742293,
     "user": {
      "displayName": "박은천",
      "photoUrl": "",
      "userId": "14521844370247226015"
     },
     "user_tz": -540
    },
    "id": "gvl7pMZthUwH",
    "outputId": "71533282-661c-411d-b48a-166b50d890c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = [1], it's a 'cat' picture.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of a picture\n",
    "index = 50\n",
    "plt.imshow(train_set_x_orig[index])\n",
    "print (\"y = \" + str(train_set_y[:, index]) + \", it's a '\" + classes[np.squeeze(train_set_y[:, index])].decode(\"utf-8\") +  \"' picture.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "geG-NQ1ahUwJ"
   },
   "source": [
    "### 딥러닝에서의 많은 버그들은 matrix/vector의 차원이 서로 맞지 않기 때문에 발생합니다. 만약 matrix/vector의 차원을 제대로 잡을 수 있으면 수많은 버그를 예방하실 수 있습니다.\n",
    "\n",
    "## <font color=\"blue\"> Question 1\n",
    "\n",
    "**문제:** 아래의 값에 적당한 값을 할당하시오:\n",
    "- m_train (number of training examples)\n",
    "- m_test (number of test examples)\n",
    "- num_px (= height = width of a training image)\n",
    "\n",
    "**힌트:** `train_set_x_orig.shape` = (m_train, num_px, num_px, 3). 예를 들어, `m_train`은 `train_set_x_orig.shape[0]`를 통해 접근할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UN25TJi6hUwK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: m_train = 200\n",
      "Number of testing examples: m_test = 50\n",
      "Height/Width of each image: num_px = 64\n",
      "Each image is of size: (64, 64, 3)\n",
      "train_set_x shape: (200, 64, 64, 3)\n",
      "train_set_y shape: (1, 200)\n",
      "test_set_x shape: (50, 64, 64, 3)\n",
      "test_set_y shape: (1, 50)\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ### (≈ 3 lines of code)\n",
    "m_train = train_set_x_orig.shape[?]\n",
    "m_test = test_set_x_orig.shape[?]\n",
    "num_px = train_set_x_orig.shape[?]\n",
    "### END CODE HERE ###\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "print (\"Height/Width of each image: num_px = \" + str(num_px))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"train_set_x shape: \" + str(train_set_x_orig.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x shape: \" + str(test_set_x_orig.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m0fU9wgahUwL"
   },
   "source": [
    "**값이 오른쪽 table과 같다면 정답입니다**: \n",
    "<table style=\"width:15%\">\n",
    "  <tr>\n",
    "    <td>**m_train**</td>\n",
    "    <td> 200 </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**m_test**</td>\n",
    "    <td> 50 </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**num_px**</td>\n",
    "    <td> 64 </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8dvIATuShUwM"
   },
   "source": [
    "### 2-3) data preprocess \n",
    "\n",
    "#### 1> flatten\n",
    "\n",
    "image dataset은 4d array\n",
    "\n",
    "image 자체는 3d array이지만 이를 딥러닝 모델 안에 넣으려면 1d array꼴로 만들어야 넣을 수 있습니다.\n",
    "\n",
    "그래서 (num_px, num_px, 3)에서 (num_px $*$ num_px $*$ 3, 1)꼴로 만들어야 합니다. 3주차에 배운 numpy 함수로 구현해봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_lvnApNMhUwN"
   },
   "source": [
    "## <font color=\"blue\"> Question 2\n",
    "\n",
    "**문제:** training and test data sets을 reshape해서 images of size (num_px, num_px, 3)가 (num\\_px $*$ num\\_px $*$ 3, 1) 형태로 되게 한다.\n",
    "\n",
    "**hint:** A trick when you want to flatten a matrix X of shape (a,b,c,d) to a matrix X_flatten of shape (b$*$c$*$d, a) is to use: \n",
    "```python\n",
    "X_flatten = X.reshape(X.shape[0], -1).T      # X.T is the transpose of X\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eFKHY6ZShUwN"
   },
   "outputs": [],
   "source": [
    "# Reshape the training and test examples\n",
    "\n",
    "### START CODE HERE ### (≈ 2 lines of code)\n",
    "train_set_x_flatten = train_set_x_orig.reshape().T\n",
    "test_set_x_flatten = \n",
    "### END CODE HERE ###\n",
    "\n",
    "print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x_flatten shape: \" + str(test_set_x_flatten.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y2HCXcc_hUwP"
   },
   "source": [
    "**값이 오른쪽 table과 같다면 정답입니다**: \n",
    "\n",
    "<table style=\"width:35%\">\n",
    "  <tr>\n",
    "    <td>**train_set_x_flatten shape**</td>\n",
    "    <td> (12288, 200)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>**train_set_y shape**</td>\n",
    "    <td>(1, 200)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>**test_set_x_flatten shape**</td>\n",
    "    <td>(12288, 50)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>**test_set_y shape**</td>\n",
    "    <td>(1, 50)</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QG65cJdrhUwP"
   },
   "source": [
    "#### 2> normalization\n",
    "\n",
    "image의 pixel 값은 모두 0~255의 값을 가집니다.\n",
    "\n",
    "경험적으로 이미지 픽셀값의 범위를 0~1로 만들면 학습이 잘 됩니다. \n",
    "\n",
    "좀 더 자세한 사항은 7주차에 안내하겠습니다. 그 때는 이미지 말고 csv파일도 normalize 해보는 구체적인 방법도 배울 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ur07hvOhUwQ"
   },
   "outputs": [],
   "source": [
    "train_set_x = train_set_x_flatten/255.\n",
    "test_set_x = test_set_x_flatten/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zwqiW2JYhUwS"
   },
   "source": [
    "<font color='blue'>\n",
    "**기억하셔야 할 것:**\n",
    "\n",
    "데이터 전처리(pre-processing)를 위한 step은 다음과 같습니다:\n",
    "- 문제의 dimension과 shape 확인(m_train, m_test, num_px, ...)\n",
    "- 각각의 example이 (num_px \\* num_px \\* 3, 1) 모양이 되도록 데이터셋을 reshape하기\n",
    "- 데이터를 \"Normalize\"하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UE8qW8K0hUwS"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UVgAdSLshUwT"
   },
   "source": [
    "## 3. General Architecture of the learning algorithm ##\n",
    "\n",
    "Logistic regression을 사용해서 고양이 사진인지 아닌지를 분간하는 간단한 모델을 만들어보겠습니다.  \n",
    "\n",
    "\n",
    "<img src=\"images/LogReg_kiank.png\" style=\"width:650px;height:400px;\">\n",
    "\n",
    "**알고리즘의 수학적 표현**:\n",
    "\n",
    "For one example $x^{(i)}$:\n",
    "$$z^{(i)} = w^T x^{(i)} + b \\tag{1}$$\n",
    "$$\\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})\\tag{2}$$ \n",
    "$$ \\mathcal{L}(a^{(i)}, y^{(i)}) =  - y^{(i)}  \\log(a^{(i)}) - (1-y^{(i)} )  \\log(1-a^{(i)})\\tag{3}$$\n",
    "\n",
    "모든 training example에 대한 cost의 합을 구하고 examples의 개수로 나누기:\n",
    "$$ J = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(a^{(i)}, y^{(i)})\\tag{6}$$\n",
    "\n",
    "**핵심 Step**:    \n",
    "\n",
    "    - Initialize the parameters of the model  \n",
    "    - Learn the parameters for the model by minimizing the cost    \n",
    "    - Use the learned parameters to make predictions (on the test set)  \n",
    "    - Analyse the results and conclude  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A5jdvG25hUwU"
   },
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SKW1yfyWhUwU"
   },
   "source": [
    "## 4. Building the parts of our algorithm ## \n",
    "\n",
    "Neural Network를 만들기 위한 main step은 다음과 같습니다:\n",
    "1. Define the model structure (such as number of input features) \n",
    "2. Initialize the model's parameters\n",
    "3. loop:\n",
    "    - Calculate current loss (forward propagation)\n",
    "    - Compute cost function\n",
    "    - Calculate current gradient (backward propagation)\n",
    "    - Update parameters (gradient descent)\n",
    "\n",
    "위 3가지 과정을 있다가 밑에서 `model()`이라는 함수에서 한 번에 진행합니다.\n",
    "\n",
    "이를 위해서는 `model()` 함수에 들어갈 부품들을 차례차례 만들어봅니다. 딥러닝의 5가지 step을 떠올려보면서 진행해도 좋습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DNHxlRr9hUwV"
   },
   "source": [
    "### 4-0) Build sigmoid function\n",
    "\n",
    "## <font color=\"blue\"> Question 3\n",
    "\n",
    "**문제:** 아래 식을 갖는 `sigmoid()`함수를 만들어보시오.\n",
    "- $ sigmoid( w^T x + b) = \\frac{1}{1 + e^{-(w^T x + b)}} $ \n",
    "- np.exp()를 사용해서 만들어보시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LljuLRAihUwW"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: sigmoid\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of z\n",
    "\n",
    "    Arguments:\n",
    "    z -- A scalar or numpy array of any size.\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(z)\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    s = 1 /  (1 + np.exp(-z))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xugD2PTuhUwX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid([0, 2]) = [0.5        0.88079708]\n"
     ]
    }
   ],
   "source": [
    "print (\"sigmoid([0, 2]) = \" + str(sigmoid(np.array([0,2]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbiOY2TjhUwZ"
   },
   "source": [
    "**값이 오른쪽 table과 같다면 정답입니다**:  \n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>**sigmoid([0, 2])**</td>\n",
    "    <td> [ 0.5         0.88079708]</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sVLWIqw1hUwZ"
   },
   "source": [
    "### 4-1) Initializing parameters\n",
    "\n",
    "## <font color=\"blue\"> Question 4\n",
    "\n",
    "**Exercise:** 함수 내부에 있는 주석에 맞게 parameter를 initialization 하시오.\n",
    "- w는 np.zeros()를 사용해서 initialization 하시오. (dim이라는 해당 함수의 parameter를 사용하시오.)\n",
    "- b는 0을 대입하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3vt7XQaqhUwa"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_with_zeros\n",
    "\n",
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"\n",
    "    This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.\n",
    "    \n",
    "    Argument:\n",
    "    dim -- size of the w vector we want (or number of parameters in this case)\n",
    "    \n",
    "    Returns:\n",
    "    w -- initialized vector of shape (dim, 1)\n",
    "    b -- initialized scalar (corresponds to the bias)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    w = \n",
    "    b =\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    assert(w.shape == (dim, 1))\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aN-kfH84hUwc"
   },
   "outputs": [],
   "source": [
    "dim = 2\n",
    "w, b = initialize_with_zeros(dim)\n",
    "print (\"w = \" + str(w))\n",
    "print (\"b = \" + str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BBED8OxPhUwe"
   },
   "source": [
    "**값이 오른쪽 table과 같다면 정답입니다**: \n",
    "\n",
    "\n",
    "<table style=\"width:15%\">\n",
    "    <tr>\n",
    "        <td>  ** w **  </td>\n",
    "        <td> [[ 0.]\n",
    " [ 0.]] </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>  ** b **  </td>\n",
    "        <td> 0 </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "For image inputs, w will be of shape (num_px $\\times$ num_px $\\times$ 3, 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9fO-eS6ShUwe"
   },
   "source": [
    "### 4-2) Forward and Backward propagation\n",
    "\n",
    "위에서 parameter initialization하는 함수를 만들었으니 다음 step인 forward, backward propagation을 하는 함수를 만듭니다.\n",
    "\n",
    "## <font color=\"blue\"> Question 5\n",
    "\n",
    "**문제:** cost function과 gradient를 계산하고 있는 `propagate()`함수를 완성하시오.\n",
    "\n",
    "**hints**: 아래 식들을 numpy를 통해 구현하시오. (이 식을 외우지 않아도 됩니다. 구현할 줄만 알면 됩니다.)\n",
    "- (forward propagation) $A = \\sigma(w^T X + b) = (a^{(1)}, a^{(2)}, ..., a^{(m-1)}, a^{(m)})$\n",
    "- (compute cost function) $J = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)})$\n",
    "\n",
    "- 아래의 두 공식을 사용하시면 됩니다: \n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(A-Y)^T\\tag{7} $$\n",
    "$$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})\\tag{8} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "piPvSzRwhUwf"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-a6effdf8a4f1>, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-a6effdf8a4f1>\"\u001b[1;36m, line \u001b[1;32m26\u001b[0m\n\u001b[1;33m    A =                                                                        # compute activation\u001b[0m\n\u001b[1;37m                                                                                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# GRADED FUNCTION: propagate\n",
    "\n",
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function and its gradient for the propagation explained above\n",
    "\n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples)\n",
    "\n",
    "    Return:\n",
    "    cost -- negative log-likelihood cost for logistic regression\n",
    "    dw -- gradient of the loss with respect to w, thus same shape as w\n",
    "    db -- gradient of the loss with respect to b, thus same shape as b\n",
    "    \n",
    "    Tips:\n",
    "    - Write your code step by step for the propagation. np.log(), np.dot()\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # FORWARD PROPAGATION (FROM X TO COST)\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    A =                                                                        # compute activation\n",
    "    cost =                                                                     # compute cost\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # BACKWARD PROPAGATION (TO FIND GRAD)\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    dw = \n",
    "    db = \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YYzdLBxhhUwi"
   },
   "outputs": [],
   "source": [
    "w, b, X, Y = np.array([[1.],[2.]]), 2., np.array([[1.,2.,-1.],[3.,4.,-3.2]]), np.array([[1,0,1]])\n",
    "grads, cost = propagate(w, b, X, Y)\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print (\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hnMfiIDhhUwl"
   },
   "source": [
    "**값이 오른쪽 table과 같다면 정답입니다**: \n",
    "\n",
    "<table style=\"width:50%\">\n",
    "    <tr>\n",
    "        <td>  ** dw **  </td>\n",
    "      <td> [[ 0.99845601]\n",
    "     [ 2.39507239]]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>  ** db **  </td>\n",
    "        <td> 0.00145557813678 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>  ** cost **  </td>\n",
    "        <td> 5.801545319394553 </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qjhIXFsnhUwm"
   },
   "source": [
    "### 4-3) Optimization (Gradient descent)\n",
    " \n",
    "- You have initialized your parameters.\n",
    "- You are also able to compute a cost function and its gradient.\n",
    "- Now, you want to update the parameters using gradient descent.\n",
    "\n",
    "## <font color=\"blue\"> Question 6\n",
    "\n",
    "**Exercise:** gradient descent 식을 완성한다.\n",
    "    \n",
    "**hint:** For a parameter $w$, the update rule is $ w = w - \\alpha \\text{ } dw$, where $\\alpha$ is the learning rate.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pp2VN_zrhUwm"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: optimize\n",
    "\n",
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "    \"\"\"\n",
    "    This function optimizes w and b by running a gradient descent algorithm\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of shape (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- True to print the loss every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    params -- dictionary containing the weights w and bias b\n",
    "    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function\n",
    "    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.\n",
    "    \n",
    "    Tips:\n",
    "    You basically need to write down two steps and iterate through them:\n",
    "        1) Calculate the cost and the gradient for the current parameters. Use propagate().\n",
    "        2) Update the parameters using gradient descent rule for w and b.\n",
    "    \"\"\"\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        \n",
    "        # Cost and gradient calculation (≈ 1-4 lines of code)\n",
    "        ### START CODE HERE ### \n",
    "        grads, cost = \n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Retrieve derivatives from grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # update rule (≈ 2 lines of code)\n",
    "        ### START CODE HERE ###\n",
    "        w =\n",
    "        b = \n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Record the costs\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "        # Print the cost every 100 training iterations\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FJw56L0BhUwo"
   },
   "outputs": [],
   "source": [
    "params, grads, costs = optimize(w, b, X, Y, num_iterations= 100, learning_rate = 0.009, print_cost = False)\n",
    "\n",
    "print (\"w = \" + str(params[\"w\"]))\n",
    "print (\"b = \" + str(params[\"b\"]))\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ju15zAq7hUwp"
   },
   "source": [
    "**값이 오른쪽 table과 같다면 정답입니다**: \n",
    "\n",
    "<table style=\"width:40%\">\n",
    "    <tr>\n",
    "       <td> **w** </td>\n",
    "       <td>[[ 0.19033591] \n",
    "     [ 0.12259159]] </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "       <td> **b** </td>\n",
    "       <td> 1.92535983008 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "       <td> **dw** </td>\n",
    "       <td> [[ 0.67752042]\n",
    " [ 1.41625495]] </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "       <td> **db** </td>\n",
    "       <td> 0.219194504541 </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y5ufQcfThUwq"
   },
   "source": [
    "## <font color=\"blue\"> Question 7\n",
    "\n",
    "이전 `optimize()` 함수는 학습된 w와 b를 출력한다. 이제는 이 w와 b로 x(image)의 y(label)를 예측해야한다.    \n",
    "    \n",
    "**문제:** 아래 조건을 만족하는 `predict()`함수를 완성하시오. \n",
    "\n",
    "1. Calculate $\\hat{Y} = A = \\sigma(w^T X + b)$\n",
    "\n",
    "2. A의 각 원소들을 0 (if activation <= 0.5) 또는 1 (if activation > 0.5) 변환하고, 이 값들을 `Y_prediction` vector에 할당하시오. \n",
    "    \n",
    "**hint:** If you wish, you can use an `if`/`else` statement in a `for` loop (though there is also a way to vectorize this). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gFTLsgIchUwq"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: predict\n",
    "\n",
    "def predict(w, b, X):\n",
    "    '''\n",
    "    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    A = \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    for i in range(A.shape[1]):\n",
    "        \n",
    "        # Convert probabilities A[0,i] to actual predictions p[0,i]\n",
    "        ### START CODE HERE ### (≈ 4 lines of code)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    assert(Y_prediction.shape == (1, m))\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AnN3JGErhUws"
   },
   "outputs": [],
   "source": [
    "w = np.array([[0.1124579],[0.23106775]])\n",
    "b = -0.3\n",
    "X = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\n",
    "print (\"predictions = \" + str(predict(w, b, X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RVHGpwDNhUwt"
   },
   "source": [
    "**값이 오른쪽 table과 같다면 정답입니다**: \n",
    "\n",
    "<table style=\"width:30%\">\n",
    "    <tr>\n",
    "         <td>\n",
    "             **predictions**\n",
    "         </td>\n",
    "          <td>\n",
    "            [[ 1.  1.  0.]]\n",
    "         </td>  \n",
    "   </tr>\n",
    "\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iq6pHBnBhUwu"
   },
   "source": [
    "<font color='blue'>\n",
    "**기억하셔야 할 것:**  \n",
    "    \n",
    "지금까지 다음과 같은 함수들을 만드셨습니다:  \n",
    "- Initialize (w,b)  \n",
    "- Optimize the loss iteratively to learn parameters (w,b):  \n",
    "    - computing the cost and its gradient   \n",
    "    - updating the parameters using gradient descent  \n",
    "- Use the learned (w,b) to predict the labels for a given set of examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yK06z1qzhUwu"
   },
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zv1jT_5ZhUwv"
   },
   "source": [
    "## 5. Merge all functions into a model ##\n",
    "\n",
    "### 5-1) training & test model\n",
    "\n",
    "You will now see how the overall model is structured by putting together all the building blocks (functions implemented in the previous parts) together, in the right order.\n",
    "\n",
    "## <font color=\"blue\"> Question 8\n",
    "\n",
    "**문제:** 아래 조건을 만족하는 `model()`함수를 완성하시오.\n",
    "- Y_prediction_test for your predictions on the test set\n",
    "- Y_prediction_train for your predictions on the train set\n",
    "- w, costs, grads for the outputs of optimize()\n",
    "    \n",
    "**hint:** 기존에 위에서 만든 함수들을 여기서 합쳐서 Neural Network(모델)를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n6TiBVE2hUwv"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: model\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n",
    "    \"\"\"\n",
    "    Builds the logistic regression model by calling the function you've implemented previously\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set represented by a numpy array of shape (num_px * num_px * 3, m_train)\n",
    "    Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train)\n",
    "    X_test -- test set represented by a numpy array of shape (num_px * num_px * 3, m_test)\n",
    "    Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test)\n",
    "    num_iterations -- hyperparameter representing the number of iterations to optimize the parameters\n",
    "    learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()\n",
    "    print_cost -- Set to true to print the cost every 100 iterations\n",
    "    \n",
    "    Returns:\n",
    "    d -- dictionary containing information about the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # initialize parameters with zeros (≈ 1 line of code)\n",
    "    w, b = \n",
    "\n",
    "    # Gradient descent (≈ 1 line of code)\n",
    "    parameters, grads, costs = \n",
    "    \n",
    "    # Retrieve parameters w and b from dictionary \"parameters\"\n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    # Predict test/train set examples (≈ 2 lines of code)\n",
    "    Y_prediction_test = \n",
    "    Y_prediction_train =\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U1fFrTtUhUwx"
   },
   "source": [
    "Run the following cell to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kBwE0bW6hUwx"
   },
   "outputs": [],
   "source": [
    "d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.0025, print_cost = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CfTS36XOhUwz"
   },
   "source": [
    "**값이 오른쪽 table과 같다면 정답입니다**: \n",
    "\n",
    "<table style=\"width:40%\"> \n",
    "    <tr>\n",
    "        <td> **Cost after iteration 0**  </td> \n",
    "        <td> 0.693147 </td>\n",
    "    </tr>\n",
    "      <tr>\n",
    "        <td> <center> $\\vdots$ </center> </td> \n",
    "        <td> <center> $\\vdots$ </center> </td> \n",
    "    </tr>  \n",
    "    <tr>\n",
    "        <td> **Train Accuracy**  </td> \n",
    "        <td> 99.0 % </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>**Test Accuracy** </td> \n",
    "        <td> 82.0 % </td>\n",
    "    </tr>\n",
    "</table> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8oFp1CvihUw0"
   },
   "source": [
    "Let's also plot the cost function and the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6s016rbKhUw1"
   },
   "outputs": [],
   "source": [
    "# Plot learning curve (with costs)\n",
    "costs = np.squeeze(d['costs'])\n",
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title(\"Learning rate =\" + str(d[\"learning_rate\"]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KjuctKojhUw2"
   },
   "source": [
    "**생각해보기:**\n",
    "- training accuracy는 100%에 가깝습니다.\n",
    "- test accuracy는 82%입니다.\n",
    "- 이 모델은 좋은 모델일까요? \n",
    "- 지금 현상을 뭐라고 할까요? 궁금하신 분은 'overfitting'을 검색해보셔도 좋습니다. 이는 5주차에 배웁니다.\n",
    "\n",
    "매주마다 점차 더 깊은 모델에 도전해봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IJ-noCKQhUw3"
   },
   "source": [
    "**Interpretation**:\n",
    "You can see the cost decreasing. It shows that the parameters are being learned. However, you see that you could train the model even more on the training set. Try to increase the number of iterations(3000으로) in the cell above and rerun the cells. You might see that the training set accuracy goes up, but the test set accuracy goes down. This is called **overfitting.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vjt7LOuhhUw3"
   },
   "source": [
    "### 5-2) test set 하나씩 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dLA4bzp3hUw4"
   },
   "outputs": [],
   "source": [
    "# Example of a picture that was wrongly classified.\n",
    "index = 2\n",
    "plt.imshow(test_set_x[:,index].reshape((num_px, num_px, 3)))\n",
    "print (\"y = \" + str(test_set_y[:,index]) + \", you predicted that it is a \\\"\" + classes[int(d[\"Y_prediction_test\"][0,index])].decode(\"utf-8\") +  \"\\\" picture.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PxRGgLuRhUw5"
   },
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gH0r-z5RhUw5"
   },
   "source": [
    "## (Bonus) 6. Test with your own image (optional/ungraded exercise) ##\n",
    "\n",
    "여기까지 완수하신 걸 축하드립니다. 이제 자신만의 image를 가지고 지금까지 만든 모델이 어떻게 예측을 하는지 알아볼 수 있습니다:\n",
    "   1. 여러분의 이미지를 \"images\" 폴더 안에 넣습니다.\n",
    "   2. 그 이미지의 이름을 \"my_image.jpg\"로 설정합니다. (확장자가 png 등이면 실행 불가 / 반드시 jpg여야 합니다.)\n",
    "   3. 코드를 실행하면 여러분의 이미지가 고양이인지 판별합니다.(1 = cat, 0 = non-cat)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_G44LbFohUw6"
   },
   "outputs": [],
   "source": [
    "## START CODE HERE ## (PUT YOUR IMAGE NAME) \n",
    "my_image = \"my_image.jpg\"   # change this to the name of your image file \n",
    "## END CODE HERE ##\n",
    "\n",
    "# We preprocess the image to fit your algorithm.\n",
    "fname = \"images/\" + my_image\n",
    "image = pilimg.open(fname)\n",
    "image = np.array(image)\n",
    "image = image/255.\n",
    "my_image = cv2.resize(image, dsize=(num_px,num_px)).reshape((1, num_px*num_px*3)).T\n",
    "my_predicted_image = predict(d[\"w\"], d[\"b\"], my_image)\n",
    "\n",
    "plt.imshow(image)\n",
    "print(\"y = \" + str(np.squeeze(my_predicted_image)) + \", your algorithm predicts a \\\"\" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") +  \"\\\" picture.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qnIycU7ehUw7"
   },
   "source": [
    "<font color='blue'>\n",
    "**What to remember from this assignment:**\n",
    "1. Preprocessing the dataset is important.\n",
    "2. You implemented each function separately: initialize(), propagate(), optimize(). Then you built a model().\n",
    "3. Tuning the learning rate (which is an example of a \"hyperparameter\") can make a big difference to the algorithm. You will see more examples of this later in this course!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jkxm7ynphUw8"
   },
   "source": [
    "마지막으로, 지금까지 구현한 모델을 통해 아래의 것들을 시도해보실 수도 있습니다.  \n",
    "- Play with the learning rate and the number of iterations\n",
    "- Try different initialization methods and compare the results\n",
    "- Test other preprocessings (center the data, or divide each row by its standard deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hFdtRiaOhUw9"
   },
   "source": [
    "Bibliography:\n",
    "- http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/\n",
    "- https://stats.stackexchange.com/questions/211436/why-do-we-normalize-images-by-subtracting-the-datasets-image-mean-and-not-the-c"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "8dvIATuShUwM",
    "QG65cJdrhUwP",
    "DNHxlRr9hUwV",
    "sVLWIqw1hUwZ",
    "9fO-eS6ShUwe",
    "qjhIXFsnhUwm",
    "vjt7LOuhhUw3"
   ],
   "name": "Week 3 Assignment.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "XaIWT",
   "launcher_item_id": "zAgPl"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
